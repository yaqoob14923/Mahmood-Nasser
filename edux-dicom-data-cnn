import cv2
import numpy as np
import pydicom as PDCM
import matplotlib.pyplot as plt
import os
from sklearn.model_selection import train_test_split
import tensorflow as tf
from keras import layers, models, regularizers
from keras.preprocessing.image import ImageDataGenerator
# Load a DICOM file
dataset = PDCM.read_file('/kaggle/input/siim-medical-images/dicom_dir/ID_0000_AGE_0060_CONTRAST_1_CT.dcm')
# Display the pixel array and its shape
print(dataset.pixel_array)
print(dataset.pixel_array.shape)
# Show the image using matplotlib
plt.imshow(dataset.pixel_array, cmap='gray')
plt.show()
# Directory path for DICOM images
path = '/kaggle/input/siim-medical-images/dicom_dir'
# Initialize an empty list to store images
images = []
# Loop through each file in the directory
for file in os.listdir(path):
    # Read the DICOM file and extract the pixel array
    f = PDCM.read_file(os.path.join(path, file)).pixel_array
    # Resize the image to 256x256 pixels
    fr = cv2.resize(f, (256,256))
    # Append the resized image to the list
    images.append(fr)
# Convert the list of images to a numpy array and reshape it
X = np.array(images)
X = X.reshape(len(images), 256, 256, 1)
# Print the shape of the image array
print(X.shape)
# Initialize an empty list to store labels
labels = []
# Extract labels from filenames
for file in os.listdir(path):
    labels.append(file.split('_')[-2])
# Convert labels to a numpy array
Y = np.array(labels)
# Print the shape of the label array
print(Y.shape)
# Split the data into training and testing sets
xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.2)
# Normalize the pixel values to the range [0, 1]
xtrain = xtrain / xtrain.max()
xtest = xtest / xtest.max()
# Print the shape of the training data
print(xtrain.shape)
# Convert labels to one-hot encoded format
ytrain = tf.keras.utils.to_categorical(ytrain)
ytest = tf.keras.utils.to_categorical(ytest)
# Build the CNN model
model = models.Sequential()
# Add convolutional layers with L2 regularization
model.add(layers.Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001), input_shape=(256, 256, 1)))
model.add(layers.Activation('relu'))
model.add(layers.Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001)))
model.add(layers.Activation('relu'))
model.add(layers.MaxPooling2D(pool_size=(2,2)))
model.add(layers.Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001)))
model.add(layers.Activation('relu'))
model.add(layers.Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001)))
model.add(layers.Activation('relu'))
model.add(layers.MaxPooling2D(pool_size=(2,2)))
model.add(layers.Conv2D(256, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001)))
model.add(layers.Activation('relu'))
model.add(layers.Conv2D(256, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001)))
model.add(layers.Activation('relu'))
model.add(layers.Conv2D(256, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001)))
model.add(layers.Activation('relu'))
model.add(layers.MaxPooling2D(pool_size=(2,2)))
model.add(layers.Conv2D(512, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001)))
model.add(layers.Activation('relu'))
model.add(layers.Conv2D(512, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001)))
model.add(layers.Activation('relu'))
model.add(layers.Conv2D(512, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001)))
model.add(layers.Activation('relu'))
model.add(layers.MaxPooling2D(pool_size=(2,2)))
model.add(layers.Conv2D(512, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001)))
model.add(layers.Activation('relu'))
model.add(layers.Conv2D(512, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001)))
model.add(layers.Activation('relu'))
model.add(layers.Conv2D(512, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001)))
model.add(layers.Activation('relu'))
model.add(layers.MaxPooling2D(pool_size=(2,2)))
model.add(layers.Conv2D(4096, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001)))
model.add(layers.Activation('relu'))
model.add(layers.MaxPooling2D(pool_size=(2,2)))
# Flatten the output of the last pooling layer
model.add(layers.Flatten())
# Add a dense layer with 2 output units and sigmoid activation
model.add(layers.Dense(2, activation='sigmoid'))
# Print the model summary
model.summary()
# Compile the model with SGD optimizer and categorical crossentropy loss
sgd = tf.keras.optimizers.SGD(0.001)
model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])
# Data augmentation for training images
datagen = ImageDataGenerator(rotation_range=40,
                             width_shift_range=0.1,
                             height_shift_range=0.1,
                             shear_range=0.2,
                             zoom_range=0.2,
                             horizontal_flip=True,
                             brightness_range=(0.5, 1.5))

# Train the model with data augmentation
model.fit(datagen.flow(xtrain, ytrain, batch_size=10),
          epochs=100,
          validation_data=datagen.flow(xtest, ytest))
# Evaluate the model on training and testing data
train_evaluation = model.evaluate(datagen.flow(xtrain, ytrain))
test_evaluation = model.evaluate(datagen.flow(xtest, ytest))

# Print the evaluation results
print('Train evaluation:', train_evaluation)
print('Test evaluation:', test_evaluation)
